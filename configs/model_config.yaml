# =====================
# configs/model_config.yaml
# =====================
model_name: "roberta-base"          # options: bert-base-uncased, roberta-base, distilbert-base-uncased, microsoft/deberta-v3-base, allenai/longformer-base-4096
seed: 42

# Task & data
task_name: "attack_type_classification"  # free text, for bookkeeping
text_fields: [
  "Scenario Description",
  "Tools Used"
]
label_field: "Attack Type"          # choose: Attack Type, Category, MITRE Technique, Impact (etc.)

# Preprocessing
max_seq_length: 256                  # use 1024â€“4096 for Longformer
train_size: 0.8
stratify: true
remove_duplicates: true

# Training
batch_size: 16
num_epochs: 4
learning_rate: 2.0e-5
weight_decay: 0.01
warmup_ratio: 0.1

# Files & paths
data:
  raw_csv: "data/raw/cyber_attacks.csv"
  processed_dir: "data/processed"
models_dir: "models"
results_dir: "results"
run_name: "roberta_attack_type_v1"
